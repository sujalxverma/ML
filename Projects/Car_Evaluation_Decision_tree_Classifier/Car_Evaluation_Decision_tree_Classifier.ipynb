{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ruTonFIzRPz7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# to ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "9Sra5tv8Rmyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "carEvaluation = pd.read_csv(\"carEvaluation.csv\")\n",
        "columnsNames = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'Purchased']\n",
        "carEvaluation.columns = columnsNames\n",
        "carEvaluation.describe()\n",
        "# carEvaluation.isnull().sum()   :   to count null values in the dataframe.\n",
        "targetCol = 'Purchased'\n",
        "targetDF = carEvaluation[targetCol]\n",
        "carEvaluation.drop(targetCol, axis=1, inplace=True)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(carEvaluation,targetDF,test_size=0.3,random_state=42)\n",
        "X_train.shape\n"
      ],
      "metadata": {
        "id": "hRWhCllBRuFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since our data is completely categorical, so we need to transform it in such a way that our model will work it on, as generally ML works on numnerical data.\n",
        "# !pip install category_encoders    # category_encoders is not present by default\n",
        "# Feature Engineering\n",
        "import category_encoders as ce\n",
        "encoders = ce.OrdinalEncoder(['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])\n",
        "X_train = encoders.fit_transform(X_train)\n",
        "X_test = encoders.transform(X_test)"
      ],
      "metadata": {
        "id": "SBkDS-yHSuTl"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating our Decision Tree Classifier model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)   # for our first model we are using entropy as the criteria to decide the measure the quality of a split at each node.\n",
        "model_entropy.fit(X_train, y_train)\n",
        "# print(model_entropy.score(X_train, y_train))\n",
        "# print(model_entropy.score(X_test, y_test))\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0)   # for our first model we are using gini impurity as the criteria to decide the measure the quality of a split at each node.\n",
        "model_gini.fit(X_train, y_train)\n",
        "# print(model_gini.score(X_train, y_train))\n",
        "# print(modemodel_ginil_2.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "2_C3xPTPXpsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the tree structure of our models involving gini impurity as split criteria.\n",
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "from sklearn import tree\n",
        "\n",
        "tree.plot_tree(model_gini.fit(X_train, y_train))"
      ],
      "metadata": {
        "id": "vPa5aOO_Y32R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the tree structure of our models involving entropy as split criteria.\n",
        "import graphviz\n",
        "dot_data = tree.export_graphviz(model_entropy, out_file=None,\n",
        "                              feature_names=X_train.columns,\n",
        "                              class_names=y_train,\n",
        "                              filled=True, rounded=True,\n",
        "                              special_characters=True)\n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph\n",
        "\n",
        "# Now, we can take different input value and check the predicted value."
      ],
      "metadata": {
        "id": "nzfhu38yZgi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Gini Classifier Report:\")\n",
        "print(classification_report(y_test, model_gini.predict(X_test)))\n",
        "\n",
        "print(\"Entropy Classifier Report:\")\n",
        "print(classification_report(y_test, model_entropy.predict(X_test)))\n",
        "\n",
        "sample = pd.DataFrame([{\n",
        "    'buying': 'vhigh',\n",
        "    'maint': 'low',\n",
        "    'doors': '4',\n",
        "    'persons': 'more',\n",
        "    'lug_boot': 'big',\n",
        "    'safety': 'high'\n",
        "}])\n",
        "\n",
        "# Now, we can take different input value and check the predicted value.\n",
        "sample_encoded = encoders.transform(sample)\n",
        "prediction = model_gini.predict(sample_encoded)\n",
        "print(\"Predicted class:\", prediction[0])"
      ],
      "metadata": {
        "id": "1MRKXFLIeDUF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}